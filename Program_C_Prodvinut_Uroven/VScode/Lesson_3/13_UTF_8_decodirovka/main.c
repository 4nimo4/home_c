/*
//------------------------------------------------------
// Как декодировать UTF-8?
//------------------------------------------------------
В примере проверяем байт UTF-8 символа: он показывает, сколько всего байт в символе.

Справочная таблица по первому байту в UTF-8:

  Binary     Hex range   Комментарий
  0xxxxxxx   0x00..0x7F  Единственный байт однобайтного символа (ASCII)
  10xxxxxx   0x80..0xBF  Продолжающий байт: один из 1–3 байтов после первого
  110xxxxx   0xC0..0xDF  Первый байт 2-байтового символа
  1110xxxx   0xE0..0xEF  Первый байт 3-байтового символа
  11110xxx   0xF0..0xF7  Первый байт 4-байтового символа

Идея:
По первому байту (старшие биты) можно узнать, сколько байтов занимает символ,
и затем «перескакивать» по строке, считая именно символы, а не байты.
*/

#include <stdio.h>    // printf
#include <stdlib.h>
#include <string.h>   // strlen

// Функция возвращает количество байтов в одном UTF-8 символе
// по его первому байту
int numberOfBytesInChar(unsigned char val);

// Функция возвращает длину строки в UTF-8 в "символах" (code points),
// а не в байтах (в отличие от strlen)
int utf8strlen(char *s);

int main(void)
{
    // s — обычная ASCII-строка: каждый символ = 1 байт
    char s[]  = "Hello world";

    // s2 — строка с кириллицей в UTF-8.
    // Русские буквы в UTF-8 занимают по 2 байта каждая.
    char s2[] = "Привет Мир";

    // strlen считает количество БАЙТОВ до '\0':
    // для "Hello world" это 11 (10 букв + пробел),
    // для "Привет Мир" будет больше, т.к. каждая русская буква — 2 байта.
    printf("strlen(s)  = %lu\n", strlen(s));
    printf("strlen(s2) = %lu\n", strlen(s2));

    // utf8strlen считает количество символов (кодовых точек UTF-8),
    // используя numberOfBytesInChar, т.е. перескакивает по многобайтным символам.
    printf("utf8strlen(s)  = %d\n", utf8strlen(s));
    printf("utf8strlen(s2) = %d\n", utf8strlen(s2));

    return 0;
}

//------------------------------------------------------
// Определение длины UTF-8 символа по первому байту
//------------------------------------------------------
int numberOfBytesInChar(unsigned char val)
{
    // 0xxxxxxx (val < 0x80) — это ASCII-символ: 1 байт
    if (val < 0x80)
    {
        return 1;
    }
    // 110xxxxx (0xC0..0xDF) — первый байт 2-байтового символа.
    // Но сюда попадают и байты 10xxxxxx (0x80..0xBF) — продолжения.
    // Для простой оценки длины «символа» нам достаточно знать,
    // что если val >= 0x80 и < 0xE0, то мы рассматриваем это как 2-байтовый символ.
    else if (val < 0xE0)
    {
        return 2;
    }
    // 1110xxxx (0xE0..0xEF) — первый байт 3-байтового символа
    else if (val < 0xF0)
    {
        return 3;
    }
    // 11110xxx (0xF0..0xF7) — первый байт 4-байтового символа
    else
    {
        return 4;
    }
}

//------------------------------------------------------
// Подсчёт длины строки в UTF-8 в "символах"
//------------------------------------------------------
int utf8strlen(char *s)
{
    char *tmp = s;   // указатель для прохода по строке
    int len = 0;     // длина в "символах" (code points)

    // Идём до нулевого байта-терминатора '\0'
    while (*tmp)
    {
        // *tmp — первый байт очередного символа.
        // Определяем, сколько байтов он занимает,
        // и перескакиваем через весь символ.
        tmp += numberOfBytesInChar((unsigned char)*tmp);
        // Увеличиваем счётчик символов
        len++;
    }
    return len;
}